{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Dask to Compute AIA Timelags in Parallel\n",
    "## Will Barnes<sup>1</sup> and Stuart Mumford<sup>2</sup>\n",
    "### <sup>1</sup> Department of Physics and Astronomy, Rice University <sup>2</sup>University of Sheffield"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll show an example of how to use Dask to efficiently compute the timelag between two AIA channels from multi-wavelength AIA data. **The goal of this notebook is to show how Dask allows us to treat many individual FITS files as a single, out-of-core data cube.** By constructing a data cube from our stacks of FITS files for each EUV channel of AIA, we can scale the computation of the timelag in each pixel of the image across *many* computing cores. By structuring the data in this way, we are able to effectively leverage our computational resources against our large volume of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "import dask\n",
    "import dask.array as da\n",
    "import distributed\n",
    "from dask_kubernetes import KubeCluster\n",
    "import gcsfs\n",
    "from astropy.time import Time\n",
    "import astropy.io\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.io.fits.hdu.base import BITPIX2DTYPE\n",
    "import sunpy\n",
    "from sunpy.map import Map\n",
    "from sunpy.util.metadata import MetaDict\n",
    "import matplotlib.colors\n",
    "\n",
    "#from util import AIACube,AIATimelags,get_header\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to define these two datastructures for shaping many FITS files into a cube\n",
    "# and then computing timelags between multiple cubes. Ideally, these will live in a\n",
    "# separate installable module at some point.\n",
    "def validate_dtype_shape(head):\n",
    "    naxes = head['NAXIS']\n",
    "    dtype = BITPIX2DTYPE[head['BITPIX']]\n",
    "    shape = [head[f'NAXIS{n}'] for n in range(naxes, 0, -1)]\n",
    "    return dtype, shape\n",
    "\n",
    "\n",
    "def get_header(fn, hdu=0):\n",
    "    with fn as fi:\n",
    "        return MetaDict(sunpy.io.fits.get_header(fi)[hdu])\n",
    "\n",
    "\n",
    "class DelayedFITS:\n",
    "    def __init__(self, file, shape, dtype, hdu=0, verify=False):\n",
    "        self.shape = shape\n",
    "        self.dtype = dtype\n",
    "        self.file = file\n",
    "        self.hdu = hdu\n",
    "        self.verify = verify\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        with self.file as fi:\n",
    "            with astropy.io.fits.open(fi, memmap=True) as hdul:\n",
    "                if self.verify:\n",
    "                    hdul.verify('silentfix+warn')\n",
    "                return hdul[self.hdu].data[item]\n",
    "\n",
    "\n",
    "class AIACube(object):\n",
    "\n",
    "    def __init__(self, maps):\n",
    "        if not all([m.data.shape == maps[0].data.shape for m in maps]):\n",
    "            raise ValueError('All maps must have same dimensions')\n",
    "        if not all([m.data.dtype == maps[0].data.dtype for m in maps]):\n",
    "            raise ValueError('All maps must have same dtype')\n",
    "        self.maps = maps\n",
    "        self.time = self._get_time()\n",
    "\n",
    "    @classmethod\n",
    "    def from_files(cls, fits_files, **kwargs):\n",
    "        openfiles = dask.bytes.open_files(fits_files)\n",
    "        headers = cls._get_headers(openfiles, **kwargs)\n",
    "        dtype, shape = cls._get_dtype_and_shape(headers)\n",
    "        maps = cls._get_maps(openfiles, headers, dtype, shape, **kwargs)\n",
    "        return cls(maps)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_maps(openfiles, headers, dtype, shape, **kwargs):\n",
    "        hdu = kwargs.get('hdu', 0)\n",
    "        verify = kwargs.get('verify', False)\n",
    "        arrays = [da.from_array(DelayedFITS(f, shape, dtype, hdu=hdu, verify=verify), chunks=shape)\n",
    "                  for f in openfiles]\n",
    "        return [Map(a, h) for a, h in zip(arrays, headers)]\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_headers(openfiles, **kwargs):\n",
    "        client = distributed.get_client()\n",
    "        futures = client.map(get_header, openfiles, hdu=kwargs.get('hdu', 0))\n",
    "        return client.gather(futures)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_dtype_and_shape(headers):\n",
    "        dtypes = [validate_dtype_shape(h) for h in headers]\n",
    "        if not all([d == dtypes[0] for d in dtypes]):\n",
    "            raise ValueError('All maps must have same shape and dtype')\n",
    "        return dtypes[0]\n",
    "\n",
    "    def _get_time(self,):\n",
    "        return u.Quantity([(Time(m.meta['t_obs']) - Time(self.maps[0].meta['t_obs'])).to(u.s) \n",
    "                            for m in self.maps])\n",
    "\n",
    "    @property\n",
    "    def shape(self,):\n",
    "        return self.time.shape + self.maps[0].data.shape\n",
    "\n",
    "    @property\n",
    "    def dtype(self,):\n",
    "        return self.maps[0].data.dtype\n",
    "\n",
    "    @property\n",
    "    def unstacked_data(self,):\n",
    "        return [m.data for m in self.maps]\n",
    "\n",
    "    @property\n",
    "    def stacked_data(self,):\n",
    "        return da.stack(self.unstacked_data)\n",
    "\n",
    "    def rechunk(self, shape):\n",
    "        return self.stacked_data.rechunk(shape)\n",
    "\n",
    "    def average(self, **kwargs):\n",
    "        #chunks = kwargs.get('chunks', (self.shape[0], self.shape[1]//10, self.shape[2]//10))\n",
    "        #cube = self.rechunk(chunks)\n",
    "        return sunpy.map.Map(self.stacked_data.mean(axis=0, dtype=np.float64), self.maps[0].meta.copy())\n",
    "\n",
    "    def submap(self, *args, **kwargs):\n",
    "        return AIACube([m.submap(*args, **kwargs) for m in self.maps])\n",
    "    \n",
    "    \n",
    "class AIATimelags(object):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        if not all([a.shape[1:] == args[0].shape[1:] for a in args]):\n",
    "            raise ValueError('All spatial dimensions must be the same')\n",
    "        if not all([a.shape[0] == args[0].shape[0] for a in args]):\n",
    "            warnings.warn('Time dimensions are not all equal length')\n",
    "        self._cubes = {a.maps[0].meta['wavelnth']: a for a in args}\n",
    "        self.channels = sorted(list(self._cubes.keys()), key=lambda x: x)\n",
    "\n",
    "    def __getitem__(self, channel):\n",
    "        # Index\n",
    "        if type(channel) is int and channel not in self.channels:\n",
    "            channel = self.channels[channel]\n",
    "        # Convert from string\n",
    "        if type(channel) is str:\n",
    "            channel = float(channel)\n",
    "        return self._cubes[channel]\n",
    "    \n",
    "    @property\n",
    "    def needs_interpolation(self,):\n",
    "        if not all([c.shape[0] == self[0].shape[0] for c in self]):\n",
    "            return True\n",
    "        return ~np.all([u.allclose(c.time, self[0].time) for c in self])\n",
    "\n",
    "    @property\n",
    "    def timelags(self):\n",
    "        time = self._interpolate_time if self.needs_interpolation else self[0].time\n",
    "        delta_t = np.diff(time.value).cumsum()\n",
    "        return np.hstack([-delta_t[::-1], np.array([0]), delta_t]) * time.unit\n",
    "    \n",
    "    @property\n",
    "    def _interpolate_time(self,):\n",
    "        min_t = min([c.time.min() for c in self])\n",
    "        max_t = max([c.time.max() for c in self])\n",
    "        n_t = max([c.time.shape[0] for c in self])\n",
    "        return np.linspace(min_t, max_t, n_t)\n",
    "    \n",
    "    def _interpolate(self, time, cube):\n",
    "        t_interp = self._interpolate_time\n",
    "        def interp_wrapper(y):\n",
    "            return interp1d(time, y, axis=0, kind='linear', fill_value='extrapolate')(t_interp)\n",
    "        return da.map_blocks(interp_wrapper, cube, chunks=t_interp.shape+cube.chunks[1:],\n",
    "                             dtype=cube.dtype)\n",
    "\n",
    "    def cross_correlation(self, channel_a, channel_b, **kwargs):\n",
    "        # Shape must be the same in spatial direction\n",
    "        chunks = kwargs.get('chunks', (self[channel_a].shape[1]//10,\n",
    "                                       self[channel_a].shape[2]//10))\n",
    "        cube_a = self[channel_a].rechunk(self[channel_a].shape[:1]+chunks)\n",
    "        cube_b = self[channel_b].rechunk(self[channel_b].shape[:1]+chunks)\n",
    "        if self.needs_interpolation:\n",
    "            cube_a = self._interpolate(self[channel_a].time, cube_a)\n",
    "            cube_b = self._interpolate(self[channel_b].time, cube_b)\n",
    "        # Reverse the first timeseries\n",
    "        cube_a = cube_a[::-1, :, :]\n",
    "        # Normalize by mean and standard deviation\n",
    "        std_a = cube_a.std(axis=0)\n",
    "        std_a = da.where(std_a == 0, 1, std_a)\n",
    "        v_a = (cube_a - cube_a.mean(axis=0)[np.newaxis, :, :]) / std_a[np.newaxis, :, :]\n",
    "        std_b = cube_b.std(axis=0)\n",
    "        std_b = da.where(std_b == 0, 1, std_b)\n",
    "        v_b = (cube_b - cube_b.mean(axis=0)[np.newaxis, :, :]) / std_b[np.newaxis, :, :]\n",
    "        # FFT of both channels\n",
    "        fft_a = da.fft.rfft(v_a, axis=0, n=self.timelags.shape[0])\n",
    "        fft_b = da.fft.rfft(v_b, axis=0, n=self.timelags.shape[0])\n",
    "        # Inverse of product of FFTS to get cross-correlation (by convolution theorem)\n",
    "        cc = da.fft.irfft(fft_a * fft_b, axis=0, n=self.timelags.shape[0])\n",
    "        # Normalize by the length of the timeseries\n",
    "        return cc / cube_a.shape[0]\n",
    "\n",
    "    def make_correlation_map(self, channel_a, channel_b, **kwargs):\n",
    "        cc = self.cross_correlation(channel_a, channel_b, **kwargs)\n",
    "        bounds = kwargs.get('timelag_bounds', None)\n",
    "        if bounds is not None:\n",
    "            indices, = np.where(np.logical_and(self.timelags >= bounds[0],\n",
    "                                               self.timelags <= bounds[1]))\n",
    "            start = indices[0]\n",
    "            stop = indices[-1] + 1\n",
    "        else:\n",
    "            start = 0\n",
    "            stop = self.timelags.shape[0] + 1\n",
    "        max_cc = cc[start:stop, :, :].max(axis=0).compute()\n",
    "        meta = self[channel_a].maps[0].meta.copy()\n",
    "        del meta['instrume']\n",
    "        del meta['t_obs']\n",
    "        del meta['wavelnth']\n",
    "        meta['bunit'] = ''\n",
    "        meta['comment'] = f'{channel_a}-{channel_b} cross-correlation'\n",
    "        plot_settings = {'cmap': 'plasma'}\n",
    "        plot_settings.update(kwargs.get('plot_settings', {}))\n",
    "        correlation_map = sunpy.map.GenericMap(max_cc, meta, plot_settings=plot_settings)\n",
    "\n",
    "        return correlation_map\n",
    "\n",
    "    def make_timelag_map(self, channel_a, channel_b, **kwargs):\n",
    "        cc = self.cross_correlation(channel_a, channel_b, **kwargs)\n",
    "        bounds = kwargs.get('timelag_bounds', None)\n",
    "        if bounds is not None:\n",
    "            indices, = np.where(np.logical_and(self.timelags >= bounds[0],\n",
    "                                               self.timelags <= bounds[1]))\n",
    "            start = indices[0]\n",
    "            stop = indices[-1] + 1\n",
    "        else:\n",
    "            start = 0\n",
    "            stop = self.timelags.shape[0] + 1\n",
    "        i_max_cc = cc[start:stop, :, :].argmax(axis=0).compute()\n",
    "        max_timelag = self.timelags[start:stop][i_max_cc]\n",
    "        meta = self[channel_a].maps[0].meta.copy()\n",
    "        del meta['instrume']\n",
    "        del meta['t_obs']\n",
    "        del meta['wavelnth']\n",
    "        meta['bunit'] = 's'\n",
    "        meta['comment'] = f'{channel_a}-{channel_b} timelag'\n",
    "        plot_settings = {'cmap': 'RdBu_r', 'vmin': self.timelags[start:stop].value.min(),\n",
    "                         'vmax': self.timelags[start:stop].value.max()}\n",
    "        plot_settings.update(kwargs.get('plot_settings', {}))\n",
    "        timelag_map = sunpy.map.GenericMap(max_timelag, meta.copy(),\n",
    "                                           plot_settings=plot_settings.copy())\n",
    "        return timelag_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using a set of AIA data that has already been uploaded to Pangeo. This data consists of 6 hours of consecutive full-disk observations in the six EUV passbands of the AIA instrument: 94, 131, 171, 193, 211, and 335 Å.\n",
    "\n",
    "Additionally, we've also created a \"prepped\" and \"derotated\" version of this dataset in which we've scaled all channels to a common resolution and removed the effect of differential rotation on the Sun such that, over time, the same pixel corresponds (approximately) to the same patch of Sun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs = gcsfs.GCSFileSystem()\n",
    "sorted(gcs.ls('pangeo-data/SDO_AIA_Images/diffrot/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = 'gcs://pangeo-data/SDO_AIA_Images/diffrot/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dask_gateway import GatewayCluster\n",
    "cluster = GatewayCluster()\n",
    "cluster.scale(50)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = distributed.Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cubes from FITS Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted previously, AIA data are stored in the FITS format, where the 4K-by-4K image at each timestep and wavelength is stored in an individual file. This means to form a timeseries for a given wavelength, we need to combine 6 hours worth of data. At a 12 s cadence, this works out to 1800 files per wavelength. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a data cube for the 171 Å channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = AIACube.from_files(os.path.join(SAVE_DIR, '171/*.fits' ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we've only read in the metadata and not the actual data. This is the *lazy* part of structure. The data is only read in when needed. However, we can still treat it much like a \"dense\" data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.shape # time, space, space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "cube.maps[0].plot(vmin=1e2,vmax=1e4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also identify the active region (AR) we are interested in. Note that we can crop each map in the same place as we have already removed the effect of the rotation of the Sun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = cube.maps[0]\n",
    "blc = SkyCoord(-600*u.arcsec,-150*u.arcsec,frame=m.coordinate_frame)\n",
    "trc = SkyCoord(-200*u.arcsec,250*u.arcsec,frame=m.coordinate_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6,6))\n",
    "m_sub = m.submap(blc,trc)\n",
    "ax = fig.gca(projection=m_sub)\n",
    "m_sub.plot(axes=ax,title=False,vmin=1e2,vmax=1e4)\n",
    "m_sub.draw_rectangle(blc,(trc.Tx - blc.Tx), (trc.Ty - blc.Ty), color='C0', lw=3)\n",
    "ax.grid(alpha=0)\n",
    "m_sub.draw_grid(axes=ax,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we can take a time average over the whole cube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_average = cube.average()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the average is only computed when we need it. Until then, the data is represented as a Dask array, though we do have access to all of the necessary metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: This takes a few minutes and can be skipped**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "cube_average.plot(title=False,vmin=1e2,vmax=1e4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a cube for each wavelength. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = [94,131,171,193,211,335]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: This may take a few minutes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cubes = [AIACube.from_files(os.path.join(SAVE_DIR, f'{c:03d}/*.fits' )) for c in channels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to normalize each channel to the exposure time. This is typically part of the \"prepping\" process. We can do this simply by dividing each map in each cube by the exposure time as found in the map metadata. We'll also only take every 10th map to reduce the compute time. This reduces our data from the 12 s cadence of the AIA instrument to a 2 minute time resolution. The computation is just a bit slower at the full cadence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cubes = [AIACube([Map(m.data/m.meta['exptime'], m.meta) for m in c.maps[::10]]) for c in cubes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we'll add the cropping (or submap) step to our pipeline since we are only interested in computing the timelags for one particular active region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: This may take a few minutes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cubes = [c.submap(blc,trc) for c in cubes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timelags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do some science, we want to calculate the timelag in each pixel of our map. The **timelag**, or the delay which maximizes the cross-correlation between two timeseries, is a useful quantity for understanding the thermal evolution of the coronal plasma between the passbands of the AIA instrument.\n",
    "\n",
    "In temperature space, the EUV passbands on AIA have the following structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://iopscience.iop.org/0004-637X/753/1/35/downloadFigure/figure/apj431449f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the so-called \"temperature response functions\" and they show approximately what temperatures each channel or passband is sensitive too.\n",
    "\n",
    "As a blob of coronal plasma cools from 10 MK down to below 1 MK, we expect to see the intensity peak in consecutively cooler channels. If we then compute the cross-correlate of the intensity timeseries in two different channels as a function of the temporal offset between those two timeseries, the offset which maximizes the cross-correlation is the **timelag**. The timelag can then be used as a proxy for the plasma cooling time between two passbands.\n",
    "\n",
    "This method was first applied to AIA data by [Viall and Klimchuk (2012)](http://iopscience.iop.org/article/10.1088/0004-637X/753/1/35/meta). They computed the timelag in every pixel of AR NOAA 11082 as observed by AIA. In doing so, they revealed large-scale cooing patterns across the entire active region. An example of several cross-correlation curves in a single pixel is shown below. When computing timelags between AIA channel pairs, we order the channel pairs by decreasing temperature such that a positive timelag implies the peak in the hot channel preceeded the peak in the cooler channel. **Using this convention, a positive timelag implies cooling plasma.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://iopscience.iop.org/0004-637X/753/1/35/downloadFigure/figure/apj431449f4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, we can express the timelag in terms of a Fourier transform, making it very simple to compute with Dask. We can express the cross-correlation $\\mathcal{C}$ between two channels $A$ and $B$ as,\n",
    "\n",
    "$$\n",
    "    \\mathcal{C}_{AB}(\\tau) = \\mathcal{I}_A(t)\\star\\mathcal{I}_B(t) = \\mathcal{I}_A(-t)\\ast\\mathcal{I}_B(t)\n",
    "$$\n",
    "\n",
    "where $\\star$ and $\\ast$ represent the correlation and convolution operators, respectively, $\\tau$ is the lag and\n",
    "\n",
    "$$\n",
    "    \\mathcal{I}_c(t)=\\frac{I_c(t)-\\bar{I}_c}{\\sigma_{c}},\n",
    "$$\n",
    "\n",
    "is the mean-subtracted and scaled intensity of channel $c$ as a function of time. Taking the fourier transform of both sides of the first equation and using the convolution theorem,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\mathcal{F}\\{\\mathcal{C}_{AB}(\\tau)\\} &= \\mathcal{F}\\{\\mathcal{I}_A(-t)\\ast\\mathcal{I}_B(t)\\},\\\\\n",
    "    &= \\mathcal{F}\\{\\mathcal{I}_A(-t)\\}\\mathcal{F}\\{\\mathcal{I}_B(t)\\}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Taking the inverse Fourier transform, $\\mathcal{F}^{-1}$, of both sides of the above expression gives,\n",
    "\n",
    "$$\n",
    "    \\mathcal{C}_{AB}(\\tau) = \\mathcal{F}^{-1}\\{\\mathcal{F}\\{\\mathcal{I}_A(-t)\\}\\mathcal{F}\\{\\mathcal{I}_B(t)\\}\\}.\n",
    "$$\n",
    "\n",
    "Scaling $\\mathcal{C}_{AB}$ by the length of the intensity timeseries $I(t)$ yields the same result as that of the correlation defined in section 2 of [Viall and Klimchuk (2012)](http://iopscience.iop.org/article/10.1088/0004-637X/753/1/35/meta). Furthermore, the **timelag** between channels $A$ and $B$ is defined as,\n",
    "$$\n",
    "    \\tau_{AB} = \\mathrm{argmax}_{\\tau}\\,\\mathcal{C}_{AB}(\\tau).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately for us, all of these operations are already implemented in `dask.array`! Since we have already shaped our data into a data cube, we just need to build the graph appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll use a class that holds cubes for all EUV wavelengths and can compute the timelag in each pixel of our observation and return the resulting timelag to a single `Map` object for each pair of AIA EUV channels. This class also includes a method (`cross_correlation`) for computing the cross-correlation in each pixel of our image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timelags = AIATimelags(*cubes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute and Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's compute a timelag in every pixel of the AR! Because the computation in each pixel is independent, we can distribute the spatial dimensions across multiple cores.\n",
    "\n",
    "Let's first compute the timelag map for the 335-171 Å channel pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_335_171 = timelags.make_timelag_map(335,171,timelag_bounds=(-3*u.hour,3*u.hour),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By creating this timelag map, we are telling Dask to execute the following chain of operations:\n",
    "\n",
    "1. Divide each map by the exposure time\n",
    "2. Crop each map to the selected active region\n",
    "3. Stack all of the maps together and \"rechunk\" the array along the time axis\n",
    "4. Interpolate the two channels to a common time array\n",
    "5. Scale the intensity by the mean and standard deviation in each pixel\n",
    "6. Compute $\\mathcal{C}_{AB}$ (see above expression) in each pixel \n",
    "7. Find the timelag $\\tau$ that maximizes $\\mathcal{C}_{AB}$\n",
    "\n",
    "Dask then takes care of farming out this task graph to all available workers. The `make_timelag_map` method then takes the resulting array and builds a SunPy map from the result with the appropriate metadata inherited from our original intensity data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot our result just as we do any other SunPy map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,10))\n",
    "ax = fig.gca(projection=tl_335_171)\n",
    "im = tl_335_171.plot(axes=ax,vmin=-7.5e3,vmax=7.5e3,cmap='RdYlBu_r',title=False)\n",
    "ax.grid(alpha=0)\n",
    "fig.colorbar(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the timelag identifies loop structures in the corona. This indicates that these *coronal loops* are evolving, specifically cooling from the 335 through the 171 passband, coherently due to the coronal plasma being confined by the magnetic field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute the maximum value of the cross-correlation in each pixel to understand how correlated the two timeseries were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_335_171 = timelags.make_correlation_map(335,171,timelag_bounds=(-3*u.hour,3*u.hour))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,10))\n",
    "ax = fig.gca(projection=cc_335_171)\n",
    "im = cc_335_171.plot(axes=ax,vmin=0,vmax=1,cmap='magma_r',title=False)\n",
    "ax.grid(alpha=0)\n",
    "fig.colorbar(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the timelag for a single channel pair in a single pixel for an equivalent timeseries would take approximately 2 ms in IDL. Assuming this was done in serial, computing the timelag over an entire active region for a single channel pair would take approximately 7.5 minutes. **Using the above method, we've accomplished the same task in about 21 s, a factor of 21 speedup!** Notably, the method presented here is also scalable such that the more computing resources we have available, the shorter our compute time (though this speedup is likely not linear!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the timelag for two channels that are a bit closer together in temperature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_335_211 = timelags.make_timelag_map(335,211,timelag_bounds=(-3*u.hour,3*u.hour),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,10))\n",
    "ax = fig.gca(projection=tl_335_211)\n",
    "im = tl_335_211.plot(axes=ax,vmin=-7.5e3,vmax=7.5e3,cmap='RdYlBu_r',title=False)\n",
    "ax.grid(alpha=0)\n",
    "fig.colorbar(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we see similar patterns for this channel pair though the timelags are shorter due to the smaller separation of the 335 and 211 channels in temperature space as compared to the 335 and 171 channels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe try one more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_94_335 = timelags.make_timelag_map(94,335,timelag_bounds=(-3*u.hour,3*u.hour),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,10))\n",
    "ax = fig.gca(projection=tl_94_335)\n",
    "im = tl_94_335.plot(axes=ax,vmin=-7.5e3,vmax=7.5e3,cmap='RdYlBu_r',title=False)\n",
    "ax.grid(alpha=0)\n",
    "fig.colorbar(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we see many more negative (blue) timelags. This is because the 94 Å channel is double peaked in temperature space (see plot above) such that it has a component hotter and cooler than the 335 Å channel. What this suggests is that the plasma is not cooling through the hot part of the 94 Å passband and helps us place bounds on the temperature evolution of these coronal loop structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
